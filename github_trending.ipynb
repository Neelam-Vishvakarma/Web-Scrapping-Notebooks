{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Notebook 05: GitHub Trending Repositories\n",
    "\n",
    "**Objective:** Scrape trending GitHub repositories' names, descriptions, language, and star count from [https://github.com/trending](https://github.com/trending)\n",
    "\n",
    ">  Uses requests + BeautifulSoup | Outputs DataFrame + CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Step 1: Import Required Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåê Step 2: Send GET Request to GitHub Trending\n",
    "url = \"https://github.com/trending\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Step 3: Extract All Repository Containers\n",
    "repo_list = soup.find_all(\"article\", class_=\"Box-row\")\n",
    "print(f\"Found {len(repo_list)} repositories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ Step 4: Loop Over Each Repo and Extract Info\n",
    "repo_names = []\n",
    "repo_descs = []\n",
    "repo_langs = []\n",
    "repo_stars = []\n",
    "\n",
    "for repo in repo_list:\n",
    "    # Repo Name\n",
    "    full_name = repo.h2.text.strip().replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "    repo_names.append(full_name)\n",
    "\n",
    "    # Description\n",
    "    desc_tag = repo.find(\"p\", class_=\"col-9\")\n",
    "    description = desc_tag.text.strip() if desc_tag else \"No description\"\n",
    "    repo_descs.append(description)\n",
    "\n",
    "    # Language\n",
    "    lang_tag = repo.find(\"span\", itemprop=\"programmingLanguage\")\n",
    "    language = lang_tag.text.strip() if lang_tag else \"Unknown\"\n",
    "    repo_langs.append(language)\n",
    "\n",
    "    # Stars\n",
    "    stars_tag = repo.find(\"a\", href=lambda x: x and x.endswith(\"/stargazers\"))\n",
    "    stars = stars_tag.text.strip().replace(\",\", \"\") if stars_tag else \"0\"\n",
    "    repo_stars.append(stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Step 5: Store Data into DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Repository\": repo_names,\n",
    "    \"Description\": repo_descs,\n",
    "    \"Language\": repo_langs,\n",
    "    \"Stars\": repo_stars\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ Step 6: Save Data to CSV\n",
    "df.to_csv(\"github_trending.csv\", index=False)\n",
    "print(\"‚úÖ Saved to github_trending.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ‚úÖ Summary\n",
    "- Scraped GitHub trending page\n",
    "- Extracted repository name, description, language, and stars\n",
    "- Stored in a clean DataFrame and saved to CSV\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
